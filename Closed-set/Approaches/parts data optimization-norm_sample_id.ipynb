{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c9c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier, Lasso\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978fa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to encode labels since labels are categorical.\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "#Mean class accuracy\n",
    "def mean_class_acc(predictions, true_labels):\n",
    "    matrix = confusion_matrix(true_labels, predictions)\n",
    "    acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94f1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "whole = sio.loadmat('whole_wolabels.mat')\n",
    "parts = sio.loadmat('parts_wolabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8277f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole\n",
    "\n",
    "#train\n",
    "train_classid = np.squeeze(whole['train_classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = whole['train_feats']\n",
    "train_imid = whole['train_imgid']\n",
    "train_imgid = []\n",
    "for item in train_imid:\n",
    "    train_imgid.append(item[0])\n",
    "train_imgid = np.squeeze(train_imgid)\n",
    "train_sampleid = whole['train_sampleid']\n",
    "\n",
    "#validation\n",
    "validation_classid = np.squeeze(whole['val_classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = whole['val_feats']\n",
    "validation_imid = whole['val_imgid']\n",
    "validation_imgid = []\n",
    "for item in validation_imid:\n",
    "    validation_imgid.append(item[0])\n",
    "validation_imgid = np.squeeze(validation_imgid)\n",
    "validation_sampleid = whole['val_sampleid']\n",
    "\n",
    "#test\n",
    "test_features = whole['test_feats']\n",
    "test_imid = whole['test_imgid']\n",
    "test_imgid = []\n",
    "for item in test_imid:\n",
    "    test_imgid.append(item[0])\n",
    "test_imgid = np.squeeze(test_imgid)\n",
    "test_sampleid = whole['test_sampleid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03476236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image ids: Counter({0: 7550, 1: 297, 2: 2})\n",
      "Train sample id shape: (7849, 1)\n",
      "Train features shape: (7849, 384)\n",
      "\n",
      "\n",
      "Validation image ids: Counter({0: 1329, 1: 50})\n",
      "Validation sample id shape: (1379, 1)\n",
      "Validation features shape: (1379, 384)\n",
      "\n",
      "\n",
      "Test image ids: Counter({0: 1407, 1: 766, 2: 189, 3: 32, 4: 30, 5: 30})\n",
      "Test sample id shape: (2454, 1)\n",
      "Test features shape: (2454, 384)\n"
     ]
    }
   ],
   "source": [
    "#whole statistics\n",
    "\n",
    "#train\n",
    "print(\"Train image ids:\", Counter(train_imgid))\n",
    "print(\"Train sample id shape:\", train_sampleid.shape)\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#validation\n",
    "print(\"Validation image ids:\", Counter(validation_imgid))\n",
    "print(\"Validation sample id shape:\", validation_sampleid.shape)\n",
    "print(\"Validation features shape:\", validation_features.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#test\n",
    "print(\"Test image ids:\", Counter(test_imgid))\n",
    "print(\"Test sample id shape:\", test_sampleid.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a54c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parts\n",
    "\n",
    "#train\n",
    "train_classid_parts = np.squeeze(parts['train_classid'])\n",
    "train_class_labels_parts = []\n",
    "for item in train_classid_parts:\n",
    "    train_class_labels_parts.append(item[0])\n",
    "train_features_parts = parts['train_feats']\n",
    "train_imid_parts = parts['train_imgid']\n",
    "train_imgid_parts = []\n",
    "for item in train_imid_parts:\n",
    "    train_imgid_parts.append(item[0])\n",
    "train_imgid_parts = np.squeeze(train_imgid_parts)\n",
    "train_sampleid_parts = parts['train_sampleid']\n",
    "train_tileid_parts = parts['train_tileid']\n",
    "\n",
    "#validation\n",
    "validation_classid_parts = np.squeeze(parts['val_classid'])\n",
    "validation_class_labels_parts = []\n",
    "for item in validation_classid_parts:\n",
    "    validation_class_labels_parts.append(item[0])\n",
    "validation_features_parts = parts['val_feats']\n",
    "validation_imid_parts = parts['val_imgid']\n",
    "validation_imgid_parts = []\n",
    "for item in validation_imid_parts:\n",
    "    validation_imgid_parts.append(item[0])\n",
    "validation_imgid_parts = np.squeeze(validation_imgid_parts)\n",
    "validation_sampleid_parts = parts['val_sampleid']\n",
    "validation_tileid_parts = parts['val_tileid']\n",
    "\n",
    "#test\n",
    "test_features_parts = parts['test_feats']\n",
    "test_imid_parts = parts['test_imgid']\n",
    "test_imgid_parts = []\n",
    "for item in test_imid_parts:\n",
    "    test_imgid_parts.append(item[0])\n",
    "test_imgid_parts = np.squeeze(test_imgid_parts)\n",
    "test_sampleid_parts = parts['test_sampleid']\n",
    "test_tileid_parts = parts['test_tileid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6db6af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts Train image ids: Counter({0: 67950, 1: 2673, 2: 18})\n",
      "Parts Train sample id shape: (70641, 1)\n",
      "Parts Train tile id shape: (70641, 2)\n",
      "Parts Train features shape: (70641, 384)\n",
      "Parts Train unique labels count: 1013\n",
      "\n",
      "\n",
      "Parts Validation image ids: Counter({0: 11961, 1: 450})\n",
      "Parts Validation sample id shape: (12411, 1)\n",
      "Parts Validation tile id shape: (12411, 2)\n",
      "Parts Validation features shape: (12411, 384)\n",
      "Parts Validation unique labels count: 1013\n",
      "\n",
      "\n",
      "Parts Test image ids: Counter({0: 12663, 1: 6894, 2: 1701, 3: 288, 4: 270, 5: 270})\n",
      "Parts Test sample id shape: (22086, 1)\n",
      "Parts Test tile id shape: (22086, 2)\n",
      "Parts Test features shape: (22086, 384)\n"
     ]
    }
   ],
   "source": [
    "#parts statistics\n",
    "\n",
    "#train\n",
    "print(\"Parts Train image ids:\", Counter(train_imgid_parts))\n",
    "print(\"Parts Train sample id shape:\", train_sampleid_parts.shape)\n",
    "print(\"Parts Train tile id shape:\", train_tileid_parts.shape)\n",
    "print(\"Parts Train features shape:\", train_features_parts.shape)\n",
    "train_unique_labels_parts = sorted(np.unique(train_class_labels_parts))\n",
    "train_unique_labels_count_parts = len(train_unique_labels_parts)\n",
    "print(\"Parts Train unique labels count:\", train_unique_labels_count_parts)\n",
    "print(\"\\n\")\n",
    "\n",
    "#validation\n",
    "print(\"Parts Validation image ids:\", Counter(validation_imgid_parts))\n",
    "print(\"Parts Validation sample id shape:\", validation_sampleid_parts.shape)\n",
    "print(\"Parts Validation tile id shape:\", validation_tileid_parts.shape)\n",
    "print(\"Parts Validation features shape:\", validation_features_parts.shape)\n",
    "validation_unique_labels_parts = sorted(np.unique(validation_class_labels_parts))\n",
    "validation_unique_labels_count_parts = len(validation_unique_labels_parts)\n",
    "print(\"Parts Validation unique labels count:\", validation_unique_labels_count_parts)\n",
    "print(\"\\n\")\n",
    "\n",
    "#test\n",
    "print(\"Parts Test image ids:\", Counter(test_imgid_parts))\n",
    "print(\"Parts Test sample id shape:\", test_sampleid_parts.shape)\n",
    "print(\"Parts Test tile id shape:\", test_tileid_parts.shape)\n",
    "print(\"Parts Test features shape:\", test_features_parts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8befa4e",
   "metadata": {},
   "source": [
    "parts data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9db03f",
   "metadata": {},
   "source": [
    "Converting into bag representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a423e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70641 384\n",
      "(7849, 3456)\n",
      "12411 384\n",
      "(1379, 3456)\n"
     ]
    }
   ],
   "source": [
    "train_n, d = train_features_parts.shape\n",
    "print(train_n,d)\n",
    "train_features_parts_bags = train_features_parts.reshape(int(train_n/9), 9*d)\n",
    "print(train_features_parts_bags.shape)\n",
    "\n",
    "val_n, d = validation_features_parts.shape\n",
    "print(val_n,d)\n",
    "validation_features_parts_bags = validation_features_parts.reshape(int(val_n/9), 9*d)\n",
    "print(validation_features_parts_bags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac3554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "Train unique labels count: 1013\n",
      "1379\n",
      "Validation unique labels count: 1013\n"
     ]
    }
   ],
   "source": [
    "#encoded train labels\n",
    "train_labels_bags, le_parts = encode_labels(train_class_labels)\n",
    "print(len(train_labels_bags))\n",
    "train_unique_labels = sorted(np.unique(train_labels_bags))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(\"Train unique labels count:\", train_unique_labels_count)\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels_bags = le_parts.transform(validation_class_labels)\n",
    "print(len(validation_labels_bags))\n",
    "validation_unique_labels = sorted(np.unique(validation_labels_bags))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(\"Validation unique labels count:\", validation_unique_labels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2657c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 3840)\n",
      "(1379, 3840)\n"
     ]
    }
   ],
   "source": [
    "combined_train_features = []\n",
    "combined_validation_features = []\n",
    "for i in range(len(train_features_parts_bags)):\n",
    "    combined_train_features.append(np.concatenate((train_features[i], train_features_parts_bags[i]), axis=None))\n",
    "print(np.array(combined_train_features).shape)\n",
    "\n",
    "for i in range(len(validation_features_parts_bags)):\n",
    "    combined_validation_features.append(np.concatenate((validation_features[i], validation_features_parts_bags[i]), axis=None))\n",
    "print(np.array(combined_validation_features).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e301520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-1 normalization\n",
    "scalar = MinMaxScaler()\n",
    "combined_train_features_norm = scalar.fit_transform(combined_train_features)\n",
    "combined_validation_features_norm = scalar.transform(combined_validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6afc7",
   "metadata": {},
   "source": [
    "Averaging by sample id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250568c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampleid_list = np.squeeze(train_sampleid)\n",
    "validation_sampleid_list = np.squeeze(validation_sampleid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39c4f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc, dc = np.array(combined_train_features_norm).shape\n",
    "train_sampleid_index = []\n",
    "combined_train_features_sm = np.zeros((nc, dc))\n",
    "for i in range(nc):\n",
    "    loc_sample_id = []\n",
    "    for j in range(nc):\n",
    "        if (train_sampleid_list[i] == train_sampleid_list[j]):\n",
    "            loc_sample_id.append(j)\n",
    "    train_sampleid_index.append(loc_sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d73ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 3840)\n"
     ]
    }
   ],
   "source": [
    "for i in range(nc):\n",
    "    temp_train_features = np.zeros(dc)\n",
    "    for j in range(len(train_sampleid_index[i])):\n",
    "        temp_train_features += combined_train_features_norm[train_sampleid_index[i][j]]\n",
    "    combined_train_features_sm[i] = temp_train_features/len(train_sampleid_index[i])\n",
    "\n",
    "print(combined_train_features_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3edd93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc, dc = np.array(combined_validation_features_norm).shape\n",
    "validation_sampleid_index = []\n",
    "combined_validation_features_sm = np.zeros((nc, dc))\n",
    "for i in range(nc):\n",
    "    loc_sample_id = []\n",
    "    for j in range(nc):\n",
    "        if (validation_sampleid_list[i] == validation_sampleid_list[j]):\n",
    "            loc_sample_id.append(j)\n",
    "    validation_sampleid_index.append(loc_sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8967764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1379, 3840)\n"
     ]
    }
   ],
   "source": [
    "for i in range(nc):\n",
    "    temp_validation_features = np.zeros(dc)\n",
    "    for j in range(len(validation_sampleid_index[i])):\n",
    "        temp_validation_features += combined_validation_features_norm[validation_sampleid_index[i][j]]\n",
    "    combined_validation_features_sm[i] = temp_validation_features/len(validation_sampleid_index[i])\n",
    "\n",
    "print(combined_validation_features_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b643bab1",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4de5c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8651196519216824\n",
      "Mean class accuracy: 0.8435693132139331\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C = 10, solver = 'liblinear', class_weight = 'balanced', random_state=0)\n",
    "clf.fit(combined_train_features_sm, train_labels_bags)\n",
    "score = clf.score(combined_validation_features_sm, validation_labels_bags)\n",
    "print(score)\n",
    "preds = clf.predict(combined_validation_features_sm)\n",
    "mean_acc = mean_class_acc(preds, validation_labels_bags)\n",
    "print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27945a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d706eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
