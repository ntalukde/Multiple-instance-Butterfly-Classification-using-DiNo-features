{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1774f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.special import gammaln, softmax  \n",
    "from scipy.linalg import solve_triangular, solve, eigh, eig\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.stats import multivariate_t\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56414127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "whole = sio.loadmat('whole_wolabels.mat')\n",
    "parts = sio.loadmat('parts_wolabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8bce01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "def Harmonic_Mean(ytest, ypred, ytrain):\n",
    "    ytest = np.array(ytest)\n",
    "    ypred = np.array(ypred)\n",
    "    true_dict = Counter(ytest)\n",
    "    prediction_dict = Counter(ypred)\n",
    "    uytest = set(ytest) #all classes present during testing may contain unseen classes \n",
    "                        # and only a subset of the seen classes\n",
    "    uytrain = set(ytrain) #classes represented during training, seen classes\n",
    "    \n",
    "    #Mean class accuracy\n",
    "    uy = list(uytest.intersection(uytrain))\n",
    "    nc = len(uy)\n",
    "    Classification_accuracy = np.zeros(nc)\n",
    "    for i in range(nc):\n",
    "        Index_of_i_th_class_true = list(np.argwhere(ytest == uy[i]).ravel())\n",
    "        Index_of_i_th_class_pred = list(np.argwhere(ypred == uy[i]).ravel())\n",
    "        tp = len(list(set(Index_of_i_th_class_true).intersection(Index_of_i_th_class_pred)))\n",
    "        Classification_accuracy[i] = tp/true_dict[uy[i]]\n",
    "    Classification_accuracy = np.mean(Classification_accuracy)\n",
    "    \n",
    "    #Out of distribution f1 score\n",
    "    uy = set(uy)\n",
    "    u_unseen_classes = list(uytest - uy)\n",
    "    Index_of_unseen_class_true = list(np.argwhere(np.isin(ytest, u_unseen_classes)).ravel())\n",
    "    Index_of_unseen_class_pred = list(np.argwhere(ypred > 5000).ravel())\n",
    "    tp = len(list(set(Index_of_unseen_class_true).intersection(Index_of_unseen_class_pred)))\n",
    "    fp = len(Index_of_unseen_class_pred) - tp\n",
    "    fn = len(Index_of_unseen_class_true) - tp\n",
    "    OOD_F1 = (2*tp)/(2*tp + fp + fn)\n",
    "    \n",
    "    harmonic_mean = 2*Classification_accuracy*OOD_F1/(Classification_accuracy+OOD_F1) \n",
    "                                    #harmonic mean of the two scores\n",
    "    \n",
    "    return Classification_accuracy, OOD_F1, harmonic_mean \n",
    "\n",
    "### Calculating class mean and covariance priors ###\n",
    "def calculate_priors(xtrain, ytrain):\n",
    "    d = xtrain.shape[1]\n",
    "    uy = np.unique(ytrain)\n",
    "    nc = len(uy)\n",
    "    mu0 = np.zeros((1,d))\n",
    "    Sigma0 = np.zeros((d,d))\n",
    "    for i in range(nc):\n",
    "        idx = (ytrain==uy[i]).flatten()\n",
    "        if len(xtrain[idx,:]) == 1:\n",
    "            mu0 += xtrain[idx,:] \n",
    "        else:\n",
    "            mu0 = mu0 + np.mean(xtrain[idx,:], axis=0)\n",
    "            Sigma0 = Sigma0 + np.cov(xtrain[idx,:], rowvar=False)\n",
    "    mu0 = mu0/nc\n",
    "    Sigma0 = Sigma0/nc\n",
    "    \n",
    "    return np.squeeze(mu0), Sigma0\n",
    "    \n",
    "### Calculating Posterior Predictive Distribution parameters ###\n",
    "def calculate_ppd_params(xtrain, ytrain, unseenclasses, Psi, mu0, m, k0, k1):\n",
    "\n",
    "    cnt = 0\n",
    "    seenclasses = np.unique(ytrain)\n",
    "    nc   = len(seenclasses) + len(unseenclasses)\n",
    "    n, d = xtrain.shape\n",
    "\n",
    "    Sig_s    = np.zeros((d,d,nc))\n",
    "    Sigmas   = np.zeros((d,d,nc))\n",
    "    mu_s     = np.zeros((nc, d))\n",
    "    v_s      = np.zeros((nc, 1), dtype=np.int32)\n",
    "    class_id = np.zeros((nc, 1))\n",
    "    \n",
    "    # The first part: for Seen classes\n",
    "    uy              = seenclasses\n",
    "    ncl             = len(uy)\n",
    "\n",
    "    for i in range(ncl):\n",
    "        idx         = np.in1d(ytrain, uy[i])\n",
    "        Xi          = xtrain[idx]\n",
    "\n",
    "        # The current selected component stats: # points, mean and scatter\n",
    "        cur_n       = np.sum(idx)\n",
    "        #print(cur_n)\n",
    "        cur_S       = (cur_n-1)*np.cov(Xi.T)\n",
    "        #print(cur_S)\n",
    "        cur_mu      = np.mean(Xi, axis=0, keepdims=True)\n",
    "        \n",
    "        # The case where only data likelihood and global priors are used and local priors are ignored. This \n",
    "        # is the case we used for seen classes as mentioned in the paper\n",
    "        v_s[cnt]        = cur_n+m-d+1\n",
    "        mu_s[cnt]       = (cur_n*cur_mu+(k0*k1/(k0+k1))*mu0)/(cur_n+(k0*k1/(k0+k1)))\n",
    "        Smu             = ((cur_n*(k0*k1/(k0+k1)))/((k0*k1/(k0+k1))+cur_n))*np.dot(cur_mu-mu0, (cur_mu-mu0).T)\n",
    "        if cur_n == 1:\n",
    "            Sig_s[:,:,cnt]  = (Psi+Smu)/(((cur_n+(k0*k1/(k0+k1)))*v_s[cnt])/(cur_n+(k0*k1/(k0+k1))+1))\n",
    "        else:\n",
    "            Sig_s[:,:,cnt]  = (Psi+cur_S+Smu)/(((cur_n+(k0*k1/(k0+k1)))*v_s[cnt])/(cur_n+(k0*k1/(k0+k1))+1))\n",
    "        if np.isnan(np.sum(Sig_s[:,:,i])):\n",
    "            print(i, \"th cov is nan\")\n",
    "            \n",
    "        class_id[cnt]   = uy[i]\n",
    "        cnt            += 1\n",
    "\n",
    "    # The second part: creating local priors for each Genus\n",
    "    ncl           = len(unseenclasses)\n",
    "    \n",
    "    # Main for loop for  Genus local priors params estimation\n",
    "    for i in range(ncl):\n",
    "        classes = unseenclasses[i]\n",
    "        #Extract corresponding data\n",
    "        idx       = np.in1d(ytrain, classes)\n",
    "        Yi        = ytrain[idx]\n",
    "        Xi        = xtrain[idx]\n",
    "        uyi       = np.unique(Yi)\n",
    "\n",
    "        # Initialize component sufficient statistics \n",
    "        ncpi      = len(uyi)\n",
    "        xkl       = np.zeros((ncpi,d))      # Component means\n",
    "        Skl       = np.zeros((d,d,ncpi))    # Component scatter matrices\n",
    "        kap       = np.zeros((ncpi,1))      # model specific\n",
    "        nkl       = np.zeros((ncpi,1))      # number of data points in the components\n",
    "\n",
    "        # Calculate  sufficient statistics for each component in meta cluster\n",
    "        for j in range(ncpi):\n",
    "            idx        = np.in1d(Yi, uyi[j])\n",
    "            nkl[j]     = np.sum(idx)\n",
    "            kap[j]     = nkl[j]*k1/(nkl[j]+k1)\n",
    "            Xij        = Xi[idx]\n",
    "            xkl[j]     = np.mean(Xij, axis=0)\n",
    "            if nkl[j] > 1:\n",
    "                Skl[:,:,j] = (nkl[j]-1)*np.cov(Xij.T)   \n",
    "\n",
    "        # Model specific parameters\n",
    "        sumkap       = np.sum(kap)\n",
    "        kaps         = (sumkap+k0)*k1/(sumkap+k0+k1)\n",
    "        sumSkl       = np.sum(Skl,axis=2)\n",
    "        muk          = (np.sum(np.multiply(xkl, kap*np.ones((1,d))), axis=0)+k0*mu0)/(sumkap+k0)\n",
    "        \n",
    "        # Unseen classes' predictive cov, mean and dof\n",
    "        v_s[cnt]         = np.sum(nkl)-ncpi+m-d+1\n",
    "        class_id[cnt]   = 5000 + cnt\n",
    "        Sigmas[:,:,cnt] = Psi+sumSkl\n",
    "        Sig_s[:,:,cnt]  = (Psi+sumSkl)/((kaps*v_s[cnt])/(kaps+1))\n",
    "        if np.isnan(np.sum(Sig_s[:,:,cnt])):\n",
    "            print(cnt, \"th cov is nan\")\n",
    "            print(Psi)\n",
    "            print(sumSkl)\n",
    "        mu_s[cnt]       = muk\n",
    "        cnt             += 1  \n",
    "\n",
    "    return Sig_s, mu_s, v_s, class_id, Sigmas \n",
    "\n",
    "### PPD calculation (Log-Likelihood of Student-t) ###\n",
    "def bayesian_cls_evaluate(xtest, all_loc_vec, all_scale_mat, all_dof, all_labels):\n",
    "    nr_classes = len(all_labels)\n",
    "    log_lik = np.zeros((xtest.shape[0], nr_classes))\n",
    "    for i in range(nr_classes):\n",
    "        log_lik[:, i] = multivariate_t.logpdf(xtest, all_loc_vec[i], \\\n",
    "                                              all_scale_mat[:, :, i], all_dof[i])\n",
    "    \n",
    "    predicted_class_ids = np.argmax(log_lik, axis=1)\n",
    "    ypred = np.zeros(len(xtest))\n",
    "    \n",
    "    for i in range(len(predicted_class_ids)):\n",
    "        ypred[i] = all_labels[predicted_class_ids[i]]\n",
    "    \n",
    "    return ypred\n",
    "\n",
    "def bayesian_cls_train(x_tr, y_tr, unseenclasses, k_0=0.1, k_1=10, m=5*500, mu_0=0, s=1):\n",
    "    s_classes   = np.unique(y_tr)   \n",
    "    d0          = x_tr.shape[1] \n",
    "    [mu_0, Sigma_0] = calculate_priors(x_tr, y_tr)\n",
    "    #print(\"Sigma_0:\", Sigma_0)\n",
    "    Psi=(m-d0-1)*Sigma_0/s\n",
    "    #print(\"Psi:\", Psi)\n",
    "\n",
    "    # Class predictive cov, mean and DoF from unconstrained model\n",
    "    #print('PPD derivation is Done!!')\n",
    "    return calculate_ppd_params(x_tr, y_tr, unseenclasses, Psi, mu_0, m, k_0, k_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b22cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "#whole\n",
    "\n",
    "#train\n",
    "train_classid = np.squeeze(whole['train_classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = whole['train_feats']\n",
    "train_imid = whole['train_imgid']\n",
    "train_imgid = []\n",
    "for item in train_imid:\n",
    "    train_imgid.append(item[0])\n",
    "train_imgid = np.squeeze(train_imgid)\n",
    "train_sampleid = whole['train_sampleid']\n",
    "\n",
    "#validation\n",
    "validation_classid = np.squeeze(whole['val_classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = whole['val_feats']\n",
    "validation_imid = whole['val_imgid']\n",
    "validation_imgid = []\n",
    "for item in validation_imid:\n",
    "    validation_imgid.append(item[0])\n",
    "validation_imgid = np.squeeze(validation_imgid)\n",
    "validation_sampleid = whole['val_sampleid']\n",
    "\n",
    "#test\n",
    "test_features = whole['test_feats']\n",
    "test_imid = whole['test_imgid']\n",
    "test_imgid = []\n",
    "for item in test_imid:\n",
    "    test_imgid.append(item[0])\n",
    "test_imgid = np.squeeze(test_imgid)\n",
    "test_sampleid = whole['test_sampleid']\n",
    "\n",
    "#encoded train labels\n",
    "train_labels, le = encode_labels(train_class_labels)\n",
    "train_unique_labels = sorted(np.unique(train_labels))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(len(train_labels))\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels = le.transform(validation_class_labels)\n",
    "validation_unique_labels = sorted(np.unique(validation_labels))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2abce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parts\n",
    "\n",
    "#train\n",
    "train_classid_parts = np.squeeze(parts['train_classid'])\n",
    "train_class_labels_parts = []\n",
    "for item in train_classid_parts:\n",
    "    train_class_labels_parts.append(item[0])\n",
    "train_features_parts = parts['train_feats']\n",
    "train_imid_parts = parts['train_imgid']\n",
    "train_imgid_parts = []\n",
    "for item in train_imid_parts:\n",
    "    train_imgid_parts.append(item[0])\n",
    "train_imgid_parts = np.squeeze(train_imgid_parts)\n",
    "train_sampleid_parts = parts['train_sampleid']\n",
    "train_tileid_parts = parts['train_tileid']\n",
    "\n",
    "#validation\n",
    "validation_classid_parts = np.squeeze(parts['val_classid'])\n",
    "validation_class_labels_parts = []\n",
    "for item in validation_classid_parts:\n",
    "    validation_class_labels_parts.append(item[0])\n",
    "validation_features_parts = parts['val_feats']\n",
    "validation_imid_parts = parts['val_imgid']\n",
    "validation_imgid_parts = []\n",
    "for item in validation_imid_parts:\n",
    "    validation_imgid_parts.append(item[0])\n",
    "validation_imgid_parts = np.squeeze(validation_imgid_parts)\n",
    "validation_sampleid_parts = parts['val_sampleid']\n",
    "validation_tileid_parts = parts['val_tileid']\n",
    "\n",
    "#test\n",
    "test_features_parts = parts['test_feats']\n",
    "test_imid_parts = parts['test_imgid']\n",
    "test_imgid_parts = []\n",
    "for item in test_imid_parts:\n",
    "    test_imgid_parts.append(item[0])\n",
    "test_imgid_parts = np.squeeze(test_imgid_parts)\n",
    "test_sampleid_parts = parts['test_sampleid']\n",
    "test_tileid_parts = parts['test_tileid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb170388",
   "metadata": {},
   "source": [
    "Minmax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fd522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_features_norm = scaler.fit_transform(train_features)\n",
    "validation_features_norm = scaler.transform(validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953dd04",
   "metadata": {},
   "source": [
    "Creating holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5745c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9228\n",
      "unique_unseen_labels: [49, 51, 60, 61, 78, 84, 86, 88, 89, 100, 103, 106, 107, 110, 111, 113, 116, 121, 132, 134, 145, 146, 148, 152, 154, 158, 168, 175, 177, 199, 205, 207, 209, 212, 221, 222, 225, 227, 232, 236, 241, 249, 251, 255, 256, 257, 272, 273, 275, 281]\n",
      "unseen_labels length: 706\n",
      "unique_seen_labels length: 963\n",
      "seen_labels index train length: 7243\n",
      "(7243, 384)\n",
      "7243\n",
      "(1985, 384)\n",
      "1985\n"
     ]
    }
   ],
   "source": [
    "# combine train and validation data labels\n",
    "total_labels = np.array(list(train_labels) + list(validation_labels))\n",
    "print(len(total_labels))\n",
    "\n",
    "validation_count_dict = Counter(validation_labels)\n",
    "#print(validation_count_dict)\n",
    "\n",
    "validation_labels_dict = sorted(validation_count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "unique_unseen_labels = []\n",
    "for i in range(75,125):\n",
    "      unique_unseen_labels.append(validation_labels_dict[i][0])\n",
    "print(\"unique_unseen_labels:\", unique_unseen_labels)\n",
    "\n",
    "unseen_labels_index = np.argwhere(np.isin(total_labels, unique_unseen_labels)).ravel()\n",
    "print(\"unseen_labels length:\", len(unseen_labels_index))\n",
    "\n",
    "#separating unseen classes from train data\n",
    "unseen_labels_index_train = np.argwhere(np.isin(train_labels, unique_unseen_labels)).ravel()\n",
    "unseen_labels_train = train_labels[unseen_labels_index_train]\n",
    "unseen_embeddings_train = train_features_norm[unseen_labels_index_train]\n",
    "\n",
    "#separating seen classes from train data\n",
    "unique_seen_labels = sorted(list(set(train_unique_labels) - set(unique_unseen_labels)))\n",
    "print(\"unique_seen_labels length:\", len(unique_seen_labels))\n",
    "\n",
    "seen_labels_index_train = np.argwhere(np.isin(train_labels, unique_seen_labels)).ravel()\n",
    "print(\"seen_labels index train length:\", len(seen_labels_index_train))\n",
    "seen_labels_train = train_labels[seen_labels_index_train].reshape(len(seen_labels_index_train)).tolist()\n",
    "seen_embeddings_train = train_features_norm[seen_labels_index_train]\n",
    "\n",
    "#Final train data\n",
    "xtrain = seen_embeddings_train\n",
    "ytrain = np.array(seen_labels_train)\n",
    "\n",
    "#final validation data\n",
    "xtest = np.vstack((validation_features_norm, unseen_embeddings_train))\n",
    "ytest = np.concatenate((validation_labels, unseen_labels_train))\n",
    "\n",
    "#print(train_embeddings)\n",
    "print(xtrain.shape)\n",
    "#print(train_labels)\n",
    "print(len(ytrain))\n",
    "#print(validation_embeddings)\n",
    "print(xtest.shape)\n",
    "#print(validation_labels)\n",
    "print(len(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3821c",
   "metadata": {},
   "source": [
    "cluster classes by genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba0b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7243\n",
      "389\n"
     ]
    }
   ],
   "source": [
    "train_class_labels = decode_labels(ytrain, le)\n",
    "print(len(train_class_labels))\n",
    "\n",
    "train_unique_class_labels = sorted(np.unique(train_class_labels))\n",
    "\n",
    "# sort list\n",
    "# essential for grouping\n",
    "train_unique_class_labels.sort()\n",
    "\n",
    "# using lambda + itertools.groupby() + split() to group similar substrings\n",
    "genus_cluster = [list(i) for j, i in groupby(train_unique_class_labels, lambda a: a.split(' ')[0])]\n",
    "\n",
    "genus_cluster_encoded = []\n",
    "for i in range(len(genus_cluster)):\n",
    "    genus_cluster_encoded.append(list(le.transform(genus_cluster[i])))\n",
    "\n",
    "print(len(genus_cluster_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83a68f",
   "metadata": {},
   "source": [
    "Train and evaluation: hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9daa7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntalukde/anaconda3/envs/NephNet3D/lib/python3.7/site-packages/ipykernel_launcher.py:93: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "/home/ntalukde/anaconda3/envs/NephNet3D/lib/python3.7/site-packages/numpy/lib/function_base.py:2542: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/ntalukde/anaconda3/envs/NephNet3D/lib/python3.7/site-packages/numpy/lib/function_base.py:2542: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from k0=0.10, k1=0.01, m=386, s=1.0:\n",
      "Mean class acc: 0.81 OOD F1: 0.27, Harmonic mean: 0.41\n",
      "Results from k0=0.10, k1=0.01, m=386, s=10.0:\n",
      "Mean class acc: 0.69 OOD F1: 0.48, Harmonic mean: 0.57\n",
      "Results from k0=0.10, k1=0.01, m=38400, s=1.0:\n",
      "Mean class acc: 0.79 OOD F1: 0.04, Harmonic mean: 0.07\n",
      "Results from k0=0.10, k1=0.01, m=38400, s=10.0:\n",
      "Mean class acc: 0.01 OOD F1: 0.52, Harmonic mean: 0.03\n",
      "Results from k0=0.10, k1=0.10, m=386, s=1.0:\n",
      "Mean class acc: 0.63 OOD F1: 0.51, Harmonic mean: 0.57\n",
      "Results from k0=0.10, k1=0.10, m=386, s=10.0:\n",
      "Mean class acc: 0.58 OOD F1: 0.49, Harmonic mean: 0.53\n",
      "Results from k0=0.10, k1=0.10, m=38400, s=1.0:\n",
      "Mean class acc: 0.79 OOD F1: 0.13, Harmonic mean: 0.22\n",
      "Results from k0=0.10, k1=0.10, m=38400, s=10.0:\n",
      "Mean class acc: 0.00 OOD F1: 0.53, Harmonic mean: 0.00\n",
      "Results from k0=0.10, k1=1.00, m=386, s=1.0:\n",
      "Mean class acc: 0.55 OOD F1: 0.40, Harmonic mean: 0.46\n",
      "Results from k0=0.10, k1=1.00, m=386, s=10.0:\n",
      "Mean class acc: 0.54 OOD F1: 0.37, Harmonic mean: 0.44\n",
      "Results from k0=0.10, k1=1.00, m=38400, s=1.0:\n",
      "Mean class acc: 0.69 OOD F1: 0.44, Harmonic mean: 0.54\n",
      "Results from k0=0.10, k1=1.00, m=38400, s=10.0:\n",
      "Mean class acc: 0.02 OOD F1: 0.53, Harmonic mean: 0.03\n",
      "Results from k0=0.10, k1=10.00, m=386, s=1.0:\n",
      "Mean class acc: 0.56 OOD F1: 0.32, Harmonic mean: 0.40\n",
      "Results from k0=0.10, k1=10.00, m=386, s=10.0:\n",
      "Mean class acc: 0.55 OOD F1: 0.29, Harmonic mean: 0.38\n",
      "Results from k0=0.10, k1=10.00, m=38400, s=1.0:\n",
      "Mean class acc: 0.61 OOD F1: 0.50, Harmonic mean: 0.55\n",
      "Results from k0=0.10, k1=10.00, m=38400, s=10.0:\n",
      "Mean class acc: 0.43 OOD F1: 0.49, Harmonic mean: 0.46\n",
      "Results from k0=1.00, k1=0.01, m=386, s=1.0:\n",
      "Mean class acc: 0.81 OOD F1: 0.27, Harmonic mean: 0.41\n",
      "Results from k0=1.00, k1=0.01, m=386, s=10.0:\n",
      "Mean class acc: 0.70 OOD F1: 0.47, Harmonic mean: 0.56\n",
      "Results from k0=1.00, k1=0.01, m=38400, s=1.0:\n",
      "Mean class acc: 0.79 OOD F1: 0.04, Harmonic mean: 0.07\n",
      "Results from k0=1.00, k1=0.01, m=38400, s=10.0:\n",
      "Mean class acc: 0.01 OOD F1: 0.52, Harmonic mean: 0.03\n",
      "Results from k0=1.00, k1=0.10, m=386, s=1.0:\n",
      "Mean class acc: 0.76 OOD F1: 0.45, Harmonic mean: 0.57\n",
      "Results from k0=1.00, k1=0.10, m=386, s=10.0:\n",
      "Mean class acc: 0.71 OOD F1: 0.47, Harmonic mean: 0.57\n",
      "Results from k0=1.00, k1=0.10, m=38400, s=1.0:\n",
      "Mean class acc: 0.79 OOD F1: 0.13, Harmonic mean: 0.22\n",
      "Results from k0=1.00, k1=0.10, m=38400, s=10.0:\n",
      "Mean class acc: 0.00 OOD F1: 0.53, Harmonic mean: 0.00\n",
      "Results from k0=1.00, k1=1.00, m=386, s=1.0:\n",
      "Mean class acc: 0.69 OOD F1: 0.47, Harmonic mean: 0.56\n",
      "Results from k0=1.00, k1=1.00, m=386, s=10.0:\n",
      "Mean class acc: 0.66 OOD F1: 0.46, Harmonic mean: 0.54\n",
      "Results from k0=1.00, k1=1.00, m=38400, s=1.0:\n",
      "Mean class acc: 0.70 OOD F1: 0.44, Harmonic mean: 0.54\n",
      "Results from k0=1.00, k1=1.00, m=38400, s=10.0:\n",
      "Mean class acc: 0.02 OOD F1: 0.53, Harmonic mean: 0.04\n",
      "Results from k0=1.00, k1=10.00, m=386, s=1.0:\n",
      "Mean class acc: 0.60 OOD F1: 0.35, Harmonic mean: 0.45\n",
      "Results from k0=1.00, k1=10.00, m=386, s=10.0:\n",
      "Mean class acc: 0.57 OOD F1: 0.33, Harmonic mean: 0.42\n",
      "Results from k0=1.00, k1=10.00, m=38400, s=1.0:\n",
      "Mean class acc: 0.63 OOD F1: 0.51, Harmonic mean: 0.56\n",
      "Results from k0=1.00, k1=10.00, m=38400, s=10.0:\n",
      "Mean class acc: 0.44 OOD F1: 0.50, Harmonic mean: 0.47\n",
      "Results from k0=10.00, k1=0.01, m=386, s=1.0:\n",
      "Mean class acc: 0.81 OOD F1: 0.27, Harmonic mean: 0.41\n",
      "Results from k0=10.00, k1=0.01, m=386, s=10.0:\n",
      "Mean class acc: 0.70 OOD F1: 0.47, Harmonic mean: 0.57\n",
      "Results from k0=10.00, k1=0.01, m=38400, s=1.0:\n",
      "Mean class acc: 0.79 OOD F1: 0.04, Harmonic mean: 0.07\n",
      "Results from k0=10.00, k1=0.01, m=38400, s=10.0:\n",
      "Mean class acc: 0.01 OOD F1: 0.52, Harmonic mean: 0.03\n",
      "Results from k0=10.00, k1=0.10, m=386, s=1.0:\n",
      "Mean class acc: 0.78 OOD F1: 0.42, Harmonic mean: 0.54\n",
      "Results from k0=10.00, k1=0.10, m=386, s=10.0:\n",
      "Mean class acc: 0.72 OOD F1: 0.46, Harmonic mean: 0.56\n",
      "Results from k0=10.00, k1=0.10, m=38400, s=1.0:\n",
      "Mean class acc: 0.79 OOD F1: 0.13, Harmonic mean: 0.22\n",
      "Results from k0=10.00, k1=0.10, m=38400, s=10.0:\n",
      "Mean class acc: 0.00 OOD F1: 0.53, Harmonic mean: 0.01\n",
      "Results from k0=10.00, k1=1.00, m=386, s=1.0:\n",
      "Mean class acc: 0.80 OOD F1: 0.30, Harmonic mean: 0.44\n",
      "Results from k0=10.00, k1=1.00, m=386, s=10.0:\n",
      "Mean class acc: 0.74 OOD F1: 0.35, Harmonic mean: 0.47\n",
      "Results from k0=10.00, k1=1.00, m=38400, s=1.0:\n",
      "Mean class acc: 0.76 OOD F1: 0.41, Harmonic mean: 0.53\n",
      "Results from k0=10.00, k1=1.00, m=38400, s=10.0:\n",
      "Mean class acc: 0.16 OOD F1: 0.54, Harmonic mean: 0.25\n",
      "Results from k0=10.00, k1=10.00, m=386, s=1.0:\n",
      "Mean class acc: 0.77 OOD F1: 0.14, Harmonic mean: 0.24\n",
      "Results from k0=10.00, k1=10.00, m=386, s=10.0:\n",
      "Mean class acc: 0.74 OOD F1: 0.17, Harmonic mean: 0.27\n",
      "Results from k0=10.00, k1=10.00, m=38400, s=1.0:\n",
      "Mean class acc: 0.73 OOD F1: 0.44, Harmonic mean: 0.55\n",
      "Results from k0=10.00, k1=10.00, m=38400, s=10.0:\n",
      "Mean class acc: 0.61 OOD F1: 0.59, Harmonic mean: 0.60\n"
     ]
    }
   ],
   "source": [
    "cluster_list = genus_cluster_encoded\n",
    "d = xtrain.shape[1]\n",
    "\n",
    "all_kappa_0s = [0.1, 1, 10]\n",
    "all_kappa_1s = [0.01, 0.1, 1, 10]\n",
    "all_ms = [d+2, 100*d]\n",
    "all_s = [1, 10]\n",
    "\n",
    "for k_0 in all_kappa_0s:\n",
    "    for k_1 in all_kappa_1s:\n",
    "        for m in all_ms:\n",
    "            for s in all_s:\n",
    "                ### PPD parameter estimation ###\n",
    "                Sig_s, mu_s, v_s, class_id, _= bayesian_cls_train(xtrain, ytrain, cluster_list, k_0=k_0, k_1=k_1, m=m, s=s)\n",
    "\n",
    "                ### Prediction phase ###\n",
    "                ypred = bayesian_cls_evaluate(xtest, mu_s, Sig_s, v_s, class_id) \n",
    "\n",
    "                Classification_accuracy, OOD_F1, harmonic_mean = Harmonic_Mean(ytest, ypred, ytrain)\n",
    "\n",
    "                print('Results from k0=%.2f, k1=%.2f, m=%d, s=%.1f:' % (k_0, k_1, m, s))\n",
    "                print('Mean class acc: %.2f OOD F1: %.2f, Harmonic mean: %.2f'%(Classification_accuracy, OOD_F1, harmonic_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc28bd",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "Results from k0=0.01, k1=0.01, m=770, s=1.0:\n",
    "Mean class acc: 0.73 OOD F1: 0.53, Harmonic mean: 0.61\n",
    "\n",
    "Results from k0=0.01, k1=0.01, m=770, s=10.0:\n",
    "Mean class acc: 0.57 OOD F1: 0.57, Harmonic mean: 0.57\n",
    "\n",
    "Results from k0=0.01, k1=1.00, m=7680, s=1.0:\n",
    "Mean class acc: 0.63 OOD F1: 0.60, Harmonic mean: 0.62\n",
    "\n",
    "Results from k0=0.01, k1=1.00, m=768000, s=1.0:\n",
    "Mean class acc: 0.64 OOD F1: 0.59, Harmonic mean: 0.61\n",
    "\n",
    "Results from k0=0.01, k1=1.00, m=76800000, s=1.0:\n",
    "Mean class acc: 0.64 OOD F1: 0.58, Harmonic mean: 0.61\n",
    "\n",
    "Results from k0=0.01, k1=10.00, m=7680, s=1.0:\n",
    "Mean class acc: 0.54 OOD F1: 0.59, Harmonic mean: 0.56\n",
    "\n",
    "Results from k0=0.10, k1=0.01, m=770, s=1.0:\n",
    "Mean class acc: 0.81 OOD F1: 0.48, Harmonic mean: 0.60\n",
    "\n",
    "Results from k0=0.10, k1=0.01, m=770, s=10.0:\n",
    "Mean class acc: 0.74 OOD F1: 0.57, Harmonic mean: 0.65\n",
    "\n",
    "Results from k0=0.10, k1=0.01, m=770, s=100.0:\n",
    "Mean class acc: 0.70 OOD F1: 0.58, Harmonic mean: 0.64\n",
    "\n",
    "Results from k0=0.10, k1=0.10, m=770, s=1.0:\n",
    "Mean class acc: 0.63 OOD F1: 0.57, Harmonic mean: 0.60\n",
    "\n",
    "Results from k0=0.10, k1=1.00, m=7680, s=1.0:\n",
    "Mean class acc: 0.63 OOD F1: 0.60, Harmonic mean: 0.62\n",
    "\n",
    "\n",
    "\n",
    "1. For m > 1e3*d harmonic mean drops to 0.\n",
    "2. For s> 10 harmonic mean drops significantly\n",
    "3. k1 >=10 then m= 1e5*d is okay, but s>1 drives harmonic mean down\n",
    "4. High k1 is bad for harmonic mean\n",
    "5. s=10 seems good for outlier detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
