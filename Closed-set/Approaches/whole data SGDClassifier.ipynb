{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbebafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2000a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to encode labels since labels are categorical.\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "#Mean class accuracy\n",
    "def mean_class_acc(predictions, true_labels):\n",
    "    matrix = confusion_matrix(true_labels, predictions)\n",
    "    acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985bc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "whole = sio.loadmat('whole_wolabels.mat')\n",
    "parts = sio.loadmat('parts_wolabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f137b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole\n",
    "\n",
    "#train\n",
    "train_classid = np.squeeze(whole['train_classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = whole['train_feats']\n",
    "train_imid = whole['train_imgid']\n",
    "train_imgid = []\n",
    "for item in train_imid:\n",
    "    train_imgid.append(item[0])\n",
    "train_imgid = np.squeeze(train_imgid)\n",
    "train_sampleid = whole['train_sampleid']\n",
    "\n",
    "#validation\n",
    "validation_classid = np.squeeze(whole['val_classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = whole['val_feats']\n",
    "validation_imid = whole['val_imgid']\n",
    "validation_imgid = []\n",
    "for item in validation_imid:\n",
    "    validation_imgid.append(item[0])\n",
    "validation_imgid = np.squeeze(validation_imgid)\n",
    "validation_sampleid = whole['val_sampleid']\n",
    "\n",
    "#test\n",
    "test_features = whole['test_feats']\n",
    "test_imid = whole['test_imgid']\n",
    "test_imgid = []\n",
    "for item in test_imid:\n",
    "    test_imgid.append(item[0])\n",
    "test_imgid = np.squeeze(test_imgid)\n",
    "test_sampleid = whole['test_sampleid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71446fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image ids: Counter({0: 7550, 1: 297, 2: 2})\n",
      "Train sample id shape: (7849, 1)\n",
      "Train features shape: (7849, 384)\n",
      "Train unique labels count: 1013\n",
      "\n",
      "\n",
      "Validation image ids: Counter({0: 1329, 1: 50})\n",
      "Validation sample id shape: (1379, 1)\n",
      "Validation features shape: (1379, 384)\n",
      "Validation unique labels count: 1013\n",
      "\n",
      "\n",
      "Test image ids: Counter({0: 1407, 1: 766, 2: 189, 3: 32, 4: 30, 5: 30})\n",
      "Test sample id shape: (2454, 1)\n",
      "Test features shape: (2454, 384)\n"
     ]
    }
   ],
   "source": [
    "#whole statistics\n",
    "\n",
    "#train\n",
    "print(\"Train image ids:\", Counter(train_imgid))\n",
    "print(\"Train sample id shape:\", train_sampleid.shape)\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "train_unique_labels = sorted(np.unique(train_class_labels))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(\"Train unique labels count:\", train_unique_labels_count)\n",
    "print(\"\\n\")\n",
    "\n",
    "#validation\n",
    "print(\"Validation image ids:\", Counter(validation_imgid))\n",
    "print(\"Validation sample id shape:\", validation_sampleid.shape)\n",
    "print(\"Validation features shape:\", validation_features.shape)\n",
    "validation_unique_labels = sorted(np.unique(validation_class_labels))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(\"Validation unique labels count:\", validation_unique_labels_count)\n",
    "print(\"\\n\")\n",
    "\n",
    "#test\n",
    "print(\"Test image ids:\", Counter(test_imgid))\n",
    "print(\"Test sample id shape:\", test_sampleid.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "159dff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score normalization\n",
    "scalar = StandardScaler()\n",
    "train_features_norm = scalar.fit_transform(train_features)\n",
    "validation_features_norm = scalar.transform(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e93b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "#encoded train labels\n",
    "train_labels, le = encode_labels(train_class_labels)\n",
    "print(len(train_labels))\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels = le.transform(validation_class_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd054e7",
   "metadata": {},
   "source": [
    "Checking effect of dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7f048",
   "metadata": {},
   "source": [
    "Normalization used is StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "defa93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dimension: 150\n",
      "Overall Accuracy: 0.7164612037708484\n",
      "Mean class accuracy: 0.6815164762844922\n",
      "PCA dimension: 200\n",
      "Overall Accuracy: 0.7106598984771574\n",
      "Mean class accuracy: 0.6761928265876933\n",
      "PCA dimension: 250\n",
      "Overall Accuracy: 0.7135605511240029\n",
      "Mean class accuracy: 0.6799440605462324\n",
      "PCA dimension: 300\n",
      "Overall Accuracy: 0.7244379985496737\n",
      "Mean class accuracy: 0.6866497438067034\n",
      "PCA dimension: 350\n",
      "Overall Accuracy: 0.7237128353879623\n",
      "Mean class accuracy: 0.68930569266206\n"
     ]
    }
   ],
   "source": [
    "N_components = [150, 200, 250, 300, 350]\n",
    "\n",
    "for n_components in N_components:\n",
    "    pca = PCA(n_components = n_components)\n",
    "    train_features_red = pca.fit_transform(train_features_norm)\n",
    "    validation_features_red = pca.transform(validation_features_norm)\n",
    "    print(\"PCA dimension:\", n_components)\n",
    "    clf = SGDClassifier(class_weight = 'balanced', random_state=0)\n",
    "    clf.fit(train_features_red, train_labels)\n",
    "    preds = clf.predict(validation_features_red)\n",
    "    score = clf.score(validation_features_red, validation_labels)\n",
    "    print(\"Overall Accuracy:\", score)\n",
    "    mean_acc = mean_class_acc(preds, validation_labels)\n",
    "    print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2d7db",
   "metadata": {},
   "source": [
    "Normalization used is MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e70a455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dimension: 150\n",
      "Overall Accuracy: 0.6838288614938361\n",
      "Mean class accuracy: 0.638095238095238\n",
      "PCA dimension: 200\n",
      "Overall Accuracy: 0.6838288614938361\n",
      "Mean class accuracy: 0.6358247543834908\n",
      "PCA dimension: 250\n",
      "Overall Accuracy: 0.6903553299492385\n",
      "Mean class accuracy: 0.6422178348140836\n",
      "PCA dimension: 300\n",
      "Overall Accuracy: 0.6983321247280638\n",
      "Mean class accuracy: 0.6493183848070324\n",
      "PCA dimension: 350\n",
      "Overall Accuracy: 0.6889050036258159\n",
      "Mean class accuracy: 0.6378014384430969\n"
     ]
    }
   ],
   "source": [
    "N_components = [150, 200, 250, 300, 350]\n",
    "\n",
    "for n_components in N_components:\n",
    "    pca = PCA(n_components = n_components)\n",
    "    train_features_red = pca.fit_transform(train_features_norm)\n",
    "    validation_features_red = pca.transform(validation_features_norm)\n",
    "    print(\"PCA dimension:\", n_components)\n",
    "    clf = SGDClassifier(class_weight = 'balanced', random_state=0)\n",
    "    clf.fit(train_features_red, train_labels)\n",
    "    preds = clf.predict(validation_features_red)\n",
    "    score = clf.score(validation_features_red, validation_labels)\n",
    "    print(\"Overall Accuracy:\", score)\n",
    "    mean_acc = mean_class_acc(preds, validation_labels)\n",
    "    print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f859e1b",
   "metadata": {},
   "source": [
    "checking effect of alpha parameter\n",
    "\n",
    "Normalization is StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95ac6608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.6838288614938361\n",
      "Mean class accuracy: 0.6309923377050721\n",
      "Overall Accuracy: 0.7229876722262509\n",
      "Mean class accuracy: 0.6715155361256052\n",
      "Overall Accuracy: 0.7229876722262509\n",
      "Mean class accuracy: 0.6878837023456964\n",
      "Overall Accuracy: 0.5431472081218274\n",
      "Mean class accuracy: 0.5433084191228318\n",
      "Overall Accuracy: 0.20522117476432197\n",
      "Mean class accuracy: 0.20533070088845018\n",
      "Overall Accuracy: 0.06453952139231327\n",
      "Mean class accuracy: 0.06498848305363605\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for a in alpha:\n",
    "    clf = SGDClassifier(alpha= a, class_weight = 'balanced', random_state=0)\n",
    "    clf.fit(train_features_norm, train_labels)\n",
    "    preds = clf.predict(validation_features_norm)\n",
    "    score = clf.score(validation_features_norm, validation_labels)\n",
    "    print(\"Overall Accuracy:\", score)\n",
    "    mean_acc = mean_class_acc(preds, validation_labels)\n",
    "    print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab467a",
   "metadata": {},
   "source": [
    "SGD Classifier on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "851e21b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229876722262509\n"
     ]
    }
   ],
   "source": [
    "#without PCA\n",
    "#normalization StandardScaler\n",
    "clf = SGDClassifier(class_weight = 'balanced', random_state=0)\n",
    "clf.fit(train_features_norm, train_labels)\n",
    "score = clf.score(validation_features_norm, validation_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14e5a8",
   "metadata": {},
   "source": [
    "Ridge Classifier on whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aeb6899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708484408992023\n"
     ]
    }
   ],
   "source": [
    "clf = RidgeClassifier(class_weight = 'balanced', random_state=0)\n",
    "clf.fit(train_features_norm,train_labels)\n",
    "score = clf.score(validation_features_norm, validation_labels)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
