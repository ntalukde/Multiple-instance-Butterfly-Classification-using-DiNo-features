{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b013c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d08f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to encode labels since labels are categorical.\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "#Mean class accuracy\n",
    "def mean_class_acc(predictions, true_labels):\n",
    "    matrix = confusion_matrix(true_labels, predictions)\n",
    "    acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1744b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "whole = sio.loadmat('whole_wolabels.mat')\n",
    "parts = sio.loadmat('parts_wolabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e19911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "#whole\n",
    "\n",
    "#train\n",
    "train_classid = np.squeeze(whole['train_classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = whole['train_feats']\n",
    "train_imid = whole['train_imgid']\n",
    "train_imgid = []\n",
    "for item in train_imid:\n",
    "    train_imgid.append(item[0])\n",
    "train_imgid = np.squeeze(train_imgid)\n",
    "train_sampleid = whole['train_sampleid']\n",
    "\n",
    "#validation\n",
    "validation_classid = np.squeeze(whole['val_classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = whole['val_feats']\n",
    "validation_imid = whole['val_imgid']\n",
    "validation_imgid = []\n",
    "for item in validation_imid:\n",
    "    validation_imgid.append(item[0])\n",
    "validation_imgid = np.squeeze(validation_imgid)\n",
    "validation_sampleid = whole['val_sampleid']\n",
    "\n",
    "#test\n",
    "test_features = whole['test_feats']\n",
    "test_imid = whole['test_imgid']\n",
    "test_imgid = []\n",
    "for item in test_imid:\n",
    "    test_imgid.append(item[0])\n",
    "test_imgid = np.squeeze(test_imgid)\n",
    "test_sampleid = whole['test_sampleid']\n",
    "\n",
    "#encoded train labels\n",
    "train_labels, le = encode_labels(train_class_labels)\n",
    "train_unique_labels = sorted(np.unique(train_labels))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(len(train_labels))\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels = le.transform(validation_class_labels)\n",
    "validation_unique_labels = sorted(np.unique(validation_labels))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32397653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70641\n",
      "12411\n"
     ]
    }
   ],
   "source": [
    "#parts\n",
    "\n",
    "#train\n",
    "train_classid_parts = np.squeeze(parts['train_classid'])\n",
    "train_class_labels_parts = []\n",
    "for item in train_classid_parts:\n",
    "    train_class_labels_parts.append(item[0])\n",
    "train_features_parts = parts['train_feats']\n",
    "train_imid_parts = parts['train_imgid']\n",
    "train_imgid_parts = []\n",
    "for item in train_imid_parts:\n",
    "    train_imgid_parts.append(item[0])\n",
    "train_imgid_parts = np.squeeze(train_imgid_parts)\n",
    "train_sampleid_parts = parts['train_sampleid']\n",
    "train_tileid_parts = parts['train_tileid']\n",
    "train_labels_parts = le.transform(train_class_labels_parts)\n",
    "print(len(train_labels_parts))\n",
    "\n",
    "#validation\n",
    "validation_classid_parts = np.squeeze(parts['val_classid'])\n",
    "validation_class_labels_parts = []\n",
    "for item in validation_classid_parts:\n",
    "    validation_class_labels_parts.append(item[0])\n",
    "validation_features_parts = parts['val_feats']\n",
    "validation_imid_parts = parts['val_imgid']\n",
    "validation_imgid_parts = []\n",
    "for item in validation_imid_parts:\n",
    "    validation_imgid_parts.append(item[0])\n",
    "validation_imgid_parts = np.squeeze(validation_imgid_parts)\n",
    "validation_sampleid_parts = parts['val_sampleid']\n",
    "validation_tileid_parts = parts['val_tileid']\n",
    "validation_labels_parts = le.transform(validation_class_labels_parts)\n",
    "print(len(validation_labels_parts))\n",
    "\n",
    "#test\n",
    "test_features_parts = parts['test_feats']\n",
    "test_imid_parts = parts['test_imgid']\n",
    "test_imgid_parts = []\n",
    "for item in test_imid_parts:\n",
    "    test_imgid_parts.append(item[0])\n",
    "test_imgid_parts = np.squeeze(test_imgid_parts)\n",
    "test_sampleid_parts = parts['test_sampleid']\n",
    "test_tileid_parts = parts['test_tileid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc4ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70641 384\n",
      "(7849, 9, 384)\n",
      "12411 384\n",
      "(1379, 9, 384)\n"
     ]
    }
   ],
   "source": [
    "train_n, d = train_features_parts.shape\n",
    "print(train_n, d)\n",
    "train_features_parts_bags = train_features_parts.reshape(int(train_n/9), 9, d)\n",
    "print(train_features_parts_bags.shape)\n",
    "\n",
    "validation_n, d = validation_features_parts.shape\n",
    "print(validation_n,d)\n",
    "validation_features_parts_bags = validation_features_parts.reshape(int(validation_n/9), 9, d)\n",
    "print(validation_features_parts_bags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682ec8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 3840)\n",
      "(1379, 3840)\n"
     ]
    }
   ],
   "source": [
    "combined_train_features = []\n",
    "combined_validation_features = []\n",
    "\n",
    "for i in range(len(train_features_parts_bags)):\n",
    "    combined_train_features.append(np.concatenate((train_features[i], train_features_parts_bags[i]), axis=None))\n",
    "combined_train_features = np.array(combined_train_features)\n",
    "print(combined_train_features.shape)\n",
    "\n",
    "for i in range(len(validation_features_parts_bags)):\n",
    "    combined_validation_features.append(np.concatenate((validation_features[i], validation_features_parts_bags[i]), axis=None))\n",
    "combined_validation_features = np.array(combined_validation_features)\n",
    "print(combined_validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac80303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-1 normalization\n",
    "scaler = MinMaxScaler()\n",
    "combined_train_features_norm = scaler.fit_transform(combined_train_features)\n",
    "combined_validation_features_norm = scaler.transform(combined_validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a6bbd",
   "metadata": {},
   "source": [
    "converting into bag representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99866a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849 3840\n",
      "(7849, 10, 384)\n",
      "1379 3840\n",
      "(1379, 10, 384)\n"
     ]
    }
   ],
   "source": [
    "train_n, d = combined_train_features_norm.shape\n",
    "print(train_n,d)\n",
    "combined_train_features_norm = combined_train_features_norm.reshape(train_n, 10, int(d/10))\n",
    "print(combined_train_features_norm.shape)\n",
    "\n",
    "val_n, d = combined_validation_features_norm.shape\n",
    "print(val_n,d)\n",
    "combined_validation_features_norm = combined_validation_features_norm.reshape(val_n, 10, int(d/10))\n",
    "print(combined_validation_features_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5154d2ab",
   "metadata": {},
   "source": [
    "training on each TILE to predict on corresponding validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bab3b9",
   "metadata": {},
   "source": [
    "whole feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5422a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_table_train = np.zeros((len(train_labels), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e2f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part: 1\n",
      "0.4674480825582877\n",
      "Mean class accuracy: 0.4409893385037512\n",
      "Part: 2\n",
      "0.5310230602624538\n",
      "Mean class accuracy: 0.5271516132057332\n",
      "Part: 3\n",
      "0.47101541597655755\n",
      "Mean class accuracy: 0.441084251186126\n",
      "Part: 4\n",
      "0.6566441584915276\n",
      "Mean class accuracy: 0.6531968328246706\n",
      "Part: 5\n",
      "0.7357625175181551\n",
      "Mean class accuracy: 0.7375596331277856\n",
      "Part: 6\n",
      "0.6489998725952351\n",
      "Mean class accuracy: 0.6393744045049086\n",
      "Part: 7\n",
      "0.29889157854503756\n",
      "Mean class accuracy: 0.28626670588099096\n",
      "Part: 8\n",
      "0.3902407950057332\n",
      "Mean class accuracy: 0.3713994305430714\n",
      "Part: 9\n",
      "0.2834756019875143\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_809193/3603076519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_train_features_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred_table_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_class_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean class accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(\"Part:\", i)\n",
    "    clf_lr = LogisticRegression(C = 10, class_weight = 'balanced', solver = 'liblinear', fit_intercept = True, random_state=0)\n",
    "    clf_lr.fit(combined_train_features_norm[:,i,:], train_labels)\n",
    "    score = clf_lr.score(combined_train_features_norm[:,0,:], train_labels)\n",
    "    print(score)\n",
    "    preds = clf_lr.predict(combined_train_features_norm[:,0,:])\n",
    "    pred_table_train[:,i] = preds\n",
    "    mean_acc = mean_class_acc(preds, train_labels)\n",
    "    print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a78e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0. 1010.  816. ...    0.  251. 1010.]\n",
      " [   0.    0.    0. ...    0. 1009.  814.]\n",
      " [   0.  764.    0. ...  255.  251.  251.]\n",
      " ...\n",
      " [   0.  922. 1012. ... 1012.  874.   95.]\n",
      " [   0.  559. 1012. ... 1012. 1012.  802.]\n",
      " [   0. 1012. 1012. ... 1012.  817.  803.]]\n"
     ]
    }
   ],
   "source": [
    "pred_table_copy = pred_table_train\n",
    "print(pred_table_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce9c7509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1010.  816.    0. ...  251. 1010.    0.]\n",
      " [   0.    0.    0. ... 1009.  814.    0.]\n",
      " [ 764.    0.    0. ...  251.  251.    0.]\n",
      " ...\n",
      " [ 922. 1012.  922. ...  874.   95.    0.]\n",
      " [ 559. 1012. 1012. ... 1012.  802.    0.]\n",
      " [1012. 1012.  559. ...  817.  803.    0.]]\n"
     ]
    }
   ],
   "source": [
    "for j in range(8):\n",
    "    pred_table_train[:, j] = pred_table_copy[:, j+1]\n",
    "\n",
    "print(pred_table_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e553e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean class accuracy: 0.26452873987367626\n"
     ]
    }
   ],
   "source": [
    "pred_table_train[:,8] = preds\n",
    "mean_acc = mean_class_acc(preds, train_labels)\n",
    "print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d33305d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1010.  816.    0. ...  251. 1010.  251.]\n",
      " [   0.    0.    0. ... 1009.  814.  257.]\n",
      " [ 764.    0.    0. ...  251.  251.  251.]\n",
      " ...\n",
      " [ 922. 1012.  922. ...  874.   95.  333.]\n",
      " [ 559. 1012. 1012. ... 1012.  802. 1012.]\n",
      " [1012. 1012.  559. ...  817.  803.  524.]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_table_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30c117bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_table_val = np.zeros((len(validation_labels), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7356b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part: 1\n",
      "0.7686729514140682\n",
      "Mean class accuracy: 0.7318737366614957\n",
      "Part: 2\n",
      "0.7070340826686005\n",
      "Mean class accuracy: 0.6567080336576882\n",
      "Part: 3\n",
      "0.7585206671501088\n",
      "Mean class accuracy: 0.7193437690969773\n",
      "Part: 4\n",
      "0.7940536620739667\n",
      "Mean class accuracy: 0.7563037653363419\n",
      "Part: 5\n",
      "0.7686729514140682\n",
      "Mean class accuracy: 0.7275231514125885\n",
      "Part: 6\n",
      "0.794778825235678\n",
      "Mean class accuracy: 0.7584191228317585\n",
      "Part: 7\n",
      "0.6990572878897752\n",
      "Mean class accuracy: 0.6482865604287122\n",
      "Part: 8\n",
      "0.6446700507614214\n",
      "Mean class accuracy: 0.5872396935082029\n",
      "Part: 9\n",
      "0.6765772298767223\n",
      "Mean class accuracy: 0.6230127391529167\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(\"Part:\", i)\n",
    "    clf_lr = LogisticRegression(C = 10, class_weight = 'balanced', solver = 'liblinear', fit_intercept = True, random_state=0)\n",
    "    clf_lr.fit(combined_train_features_norm[:,i,:], train_labels)\n",
    "    score = clf_lr.score(combined_validation_features_norm[:,i,:], validation_labels)\n",
    "    print(score)\n",
    "    preds = clf_lr.predict(combined_validation_features_norm[:,i,:])\n",
    "    pred_table_val[:, i-1] = preds\n",
    "    mean_acc = mean_class_acc(preds, validation_labels)\n",
    "    print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef8bb5",
   "metadata": {},
   "source": [
    "Run experiment with TILES predictions as features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f887b21",
   "metadata": {},
   "source": [
    "First append tiles predictions to whole features and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c190499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 393)\n",
      "(1379, 393)\n"
     ]
    }
   ],
   "source": [
    "train_appended_features = np.hstack((train_features, pred_table_train))\n",
    "print(train_appended_features.shape)\n",
    "val_appended_features = np.hstack((validation_features, pred_table_val))\n",
    "print(val_appended_features.shape)\n",
    "\n",
    "#0-1 normalization\n",
    "scaler = MinMaxScaler()\n",
    "train_appended_features_norm = scaler.fit_transform(train_appended_features)\n",
    "val_appended_features_norm = scaler.transform(val_appended_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a15146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6342371  0.49304666 0.46219741 ... 0.24578791 1.         0.24578791]\n",
      " [0.64828488 0.54959035 0.49255834 ... 0.99702676 0.80594059 0.25173439]\n",
      " [0.68417868 0.4996972  0.58441029 ... 0.24578791 0.24851485 0.24578791]\n",
      " ...\n",
      " [0.33295999 0.68719526 0.42383084 ... 0.86323092 0.09405941 0.32705649]\n",
      " [0.48816728 0.65571606 0.33013516 ... 1.         0.79405941 1.        ]\n",
      " [0.45321441 0.73079081 0.25541552 ... 0.80673935 0.7950495  0.51635282]]\n",
      "[[ 6.85525586e-01  5.19314883e-01  4.42941858e-01 ... -2.97324083e-03\n",
      "   0.00000000e+00 -2.97324083e-03]\n",
      " [ 1.60238809e-01  3.84508565e-01  4.06438963e-01 ...  4.29137760e-01\n",
      "   9.90099010e-04 -1.98216056e-03]\n",
      " [ 5.79529740e-01  5.89208812e-01  5.22164147e-01 ... -9.91080278e-04\n",
      "   1.98019802e-03 -9.91080278e-04]\n",
      " ...\n",
      " [ 5.15960979e-01  5.87168024e-01  4.41510171e-01 ...  9.98017839e-01\n",
      "   1.00000000e+00  9.98017839e-01]\n",
      " [ 6.61474527e-01  4.85201138e-01  3.77441706e-01 ...  9.99008920e-01\n",
      "   1.00099010e+00  9.99008920e-01]\n",
      " [ 4.00949751e-01  7.38362178e-01  2.43915261e-01 ...  1.00000000e+00\n",
      "   7.94059406e-01  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(train_appended_features_norm)\n",
    "print(val_appended_features_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856feb5",
   "metadata": {},
   "source": [
    "Run logistic regression with liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d51a93e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7962291515591008\n",
      "Mean class accuracy: 0.7583462605180277\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(C = 10, class_weight = 'balanced', solver = 'liblinear', fit_intercept = True, random_state=0)\n",
    "clf_lr.fit(train_appended_features_norm, train_labels)\n",
    "score = clf_lr.score(val_appended_features_norm, validation_labels)\n",
    "print(score)\n",
    "preds = clf_lr.predict(val_appended_features_norm)\n",
    "mean_acc = mean_class_acc(preds, validation_labels)\n",
    "print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc9a5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_table_val = np.zeros((len(validation_labels), 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd8785",
   "metadata": {},
   "source": [
    "weights for tiles:\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
