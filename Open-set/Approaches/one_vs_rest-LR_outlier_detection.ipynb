{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585e05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.stats import multivariate_t\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a557c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "whole = sio.loadmat('whole_wolabels.mat')\n",
    "parts = sio.loadmat('parts_wolabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "380cce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "#This function is used to encode labels since labels are categorical.\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "#Harmonic mean calculation\n",
    "def Harmonic_Mean(ytest, ypred, ytrain):\n",
    "    ytest = np.array(ytest)\n",
    "    ypred = np.array(ypred)\n",
    "    true_dict = Counter(ytest)\n",
    "    prediction_dict = Counter(ypred)\n",
    "    uytest = set(ytest) #all classes present during testing may contain unseen classes and only a subset of the seen classes\n",
    "    uytrain = set(ytrain) #classes represented during training, seen classes\n",
    "    \n",
    "    #Classification f1 score\n",
    "    uy = list(uytest.intersection(uytrain))\n",
    "    nc = len(uy)\n",
    "    Classification_F1 = np.zeros(nc)\n",
    "    for i in range(nc):\n",
    "        Index_of_i_th_class_true = list(np.argwhere(ytest == uy[i]).ravel())\n",
    "        Index_of_i_th_class_pred = list(np.argwhere(ypred == uy[i]).ravel())\n",
    "        tp = len(list(set(Index_of_i_th_class_true).intersection(Index_of_i_th_class_pred)))\n",
    "        #print(\"tp: \", tp)\n",
    "        fp = prediction_dict[uy[i]] - tp\n",
    "        #print(\"fp: \", fp)\n",
    "        fn = true_dict[uy[i]] - tp\n",
    "        #print(\"fn: \", fn)\n",
    "        Classification_F1[i] = (2*tp)/(2*tp + fp + fn)\n",
    "    Classification_F1_mean = np.mean(Classification_F1)\n",
    "    \n",
    "    #Out of distribution f1 score\n",
    "    uy = set(uy)\n",
    "    u_unseen_classes = list(uytest - uy)\n",
    "    Index_of_unseen_class_true = list(np.argwhere(np.isin(ytest, u_unseen_classes)).ravel())\n",
    "    Index_of_unseen_class_pred = list(np.argwhere(ypred == -1).ravel())\n",
    "    tp = len(list(set(Index_of_unseen_class_true).intersection(Index_of_unseen_class_pred)))\n",
    "    fp = len(Index_of_unseen_class_pred) - tp\n",
    "    fn = len(Index_of_unseen_class_true) - tp\n",
    "    OOD_F1 = (2*tp)/(2*tp + fp + fn)\n",
    "    \n",
    "    harmonic_mean = 2*Classification_F1_mean*OOD_F1/(Classification_F1_mean+OOD_F1) #harmonic mean of the two scores\n",
    "    \n",
    "    return Classification_F1_mean, OOD_F1, harmonic_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2819c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "#whole\n",
    "\n",
    "#train\n",
    "train_classid = np.squeeze(whole['train_classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = whole['train_feats']\n",
    "train_imid = whole['train_imgid']\n",
    "train_imgid = []\n",
    "for item in train_imid:\n",
    "    train_imgid.append(item[0])\n",
    "train_imgid = np.squeeze(train_imgid)\n",
    "train_sampleid = whole['train_sampleid']\n",
    "\n",
    "#validation\n",
    "validation_classid = np.squeeze(whole['val_classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = whole['val_feats']\n",
    "validation_imid = whole['val_imgid']\n",
    "validation_imgid = []\n",
    "for item in validation_imid:\n",
    "    validation_imgid.append(item[0])\n",
    "validation_imgid = np.squeeze(validation_imgid)\n",
    "validation_sampleid = whole['val_sampleid']\n",
    "\n",
    "#test\n",
    "test_features = whole['test_feats']\n",
    "test_imid = whole['test_imgid']\n",
    "test_imgid = []\n",
    "for item in test_imid:\n",
    "    test_imgid.append(item[0])\n",
    "test_imgid = np.squeeze(test_imgid)\n",
    "test_sampleid = whole['test_sampleid']\n",
    "\n",
    "#encoded train labels\n",
    "train_labels, le = encode_labels(train_class_labels)\n",
    "train_unique_labels = sorted(np.unique(train_labels))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(len(train_labels))\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels = le.transform(validation_class_labels)\n",
    "validation_unique_labels = sorted(np.unique(validation_labels))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e96435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parts\n",
    "\n",
    "#train\n",
    "train_classid_parts = np.squeeze(parts['train_classid'])\n",
    "train_class_labels_parts = []\n",
    "for item in train_classid_parts:\n",
    "    train_class_labels_parts.append(item[0])\n",
    "train_features_parts = parts['train_feats']\n",
    "train_imid_parts = parts['train_imgid']\n",
    "train_imgid_parts = []\n",
    "for item in train_imid_parts:\n",
    "    train_imgid_parts.append(item[0])\n",
    "train_imgid_parts = np.squeeze(train_imgid_parts)\n",
    "train_sampleid_parts = parts['train_sampleid']\n",
    "train_tileid_parts = parts['train_tileid']\n",
    "\n",
    "#validation\n",
    "validation_classid_parts = np.squeeze(parts['val_classid'])\n",
    "validation_class_labels_parts = []\n",
    "for item in validation_classid_parts:\n",
    "    validation_class_labels_parts.append(item[0])\n",
    "validation_features_parts = parts['val_feats']\n",
    "validation_imid_parts = parts['val_imgid']\n",
    "validation_imgid_parts = []\n",
    "for item in validation_imid_parts:\n",
    "    validation_imgid_parts.append(item[0])\n",
    "validation_imgid_parts = np.squeeze(validation_imgid_parts)\n",
    "validation_sampleid_parts = parts['val_sampleid']\n",
    "validation_tileid_parts = parts['val_tileid']\n",
    "\n",
    "#test\n",
    "test_features_parts = parts['test_feats']\n",
    "test_imid_parts = parts['test_imgid']\n",
    "test_imgid_parts = []\n",
    "for item in test_imid_parts:\n",
    "    test_imgid_parts.append(item[0])\n",
    "test_imgid_parts = np.squeeze(test_imgid_parts)\n",
    "test_sampleid_parts = parts['test_sampleid']\n",
    "test_tileid_parts = parts['test_tileid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff91276",
   "metadata": {},
   "source": [
    "combine labels to find outlier percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fea67f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9228\n"
     ]
    }
   ],
   "source": [
    "# combine train and validation data labels\n",
    "total_labels = np.array(list(train_labels) + list(validation_labels))\n",
    "print(len(total_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8f2a3",
   "metadata": {},
   "source": [
    "Converting into bag representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b905be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70641 384\n",
      "(7849, 9, 384)\n",
      "12411 384\n",
      "(1379, 9, 384)\n"
     ]
    }
   ],
   "source": [
    "train_n, d = train_features_parts.shape\n",
    "print(train_n, d)\n",
    "train_features_parts_bags = train_features_parts.reshape(int(train_n/9), 9, d)\n",
    "print(train_features_parts_bags.shape)\n",
    "\n",
    "validation_n, d = validation_features_parts.shape\n",
    "print(validation_n,d)\n",
    "validation_features_parts_bags = validation_features_parts.reshape(int(validation_n/9), 9, d)\n",
    "print(validation_features_parts_bags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55396455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 3840)\n",
      "(1379, 3840)\n"
     ]
    }
   ],
   "source": [
    "combined_train_features = []\n",
    "combined_validation_features = []\n",
    "\n",
    "for i in range(len(train_features_parts_bags)):\n",
    "    combined_train_features.append(np.concatenate((train_features[i], train_features_parts_bags[i]), axis=None))\n",
    "combined_train_features = np.array(combined_train_features)\n",
    "print(combined_train_features.shape)\n",
    "\n",
    "for i in range(len(validation_features_parts_bags)):\n",
    "    combined_validation_features.append(np.concatenate((validation_features[i], validation_features_parts_bags[i]), axis=None))\n",
    "combined_validation_features = np.array(combined_validation_features)\n",
    "print(combined_validation_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea402e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minmax\n",
    "scalar_minmax = MinMaxScaler()\n",
    "train_features_norm = scalar_minmax.fit_transform(combined_train_features)\n",
    "validation_features_norm = scalar_minmax.transform(combined_validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef9d2d",
   "metadata": {},
   "source": [
    "Create holdout dataset for outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa424fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_unseen_labels: [720, 828, 898, 907, 926, 984, 13, 16, 25, 33, 39, 49, 51, 60, 61, 78, 84, 86, 88, 89, 100, 103, 106, 107, 110, 111, 113, 116, 121, 132, 134, 145, 146, 148, 152, 154, 158, 168, 175, 177, 199, 205, 207, 209, 212, 221, 222, 225, 227, 232]\n",
      "unseen_labels length: 770\n",
      "unique_seen_labels length: 963\n",
      "seen_labels index train length: 7185\n"
     ]
    }
   ],
   "source": [
    "validation_count_dict = Counter(validation_labels)\n",
    "#print(validation_count_dict)\n",
    "\n",
    "validation_labels_dict = sorted(validation_count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "unique_unseen_labels = []\n",
    "for i in range(64,114):\n",
    "      unique_unseen_labels.append(validation_labels_dict[i][0])\n",
    "print(\"unique_unseen_labels:\", unique_unseen_labels)\n",
    "\n",
    "unseen_labels_index = np.argwhere(np.isin(total_labels, unique_unseen_labels)).ravel()\n",
    "print(\"unseen_labels length:\", len(unseen_labels_index))\n",
    "\n",
    "#separating unseen classes from train data\n",
    "unseen_labels_index_train = np.argwhere(np.isin(train_labels, unique_unseen_labels)).ravel()\n",
    "unseen_labels_train = train_labels[unseen_labels_index_train]\n",
    "unseen_embeddings_train = train_features_norm[unseen_labels_index_train]\n",
    "\n",
    "#separating seen classes from train data\n",
    "unique_seen_labels = sorted(list(set(train_unique_labels) - set(unique_unseen_labels)))\n",
    "print(\"unique_seen_labels length:\", len(unique_seen_labels))\n",
    "\n",
    "seen_labels_index_train = np.argwhere(np.isin(train_labels, unique_seen_labels)).ravel()\n",
    "print(\"seen_labels index train length:\", len(seen_labels_index_train))\n",
    "seen_labels_train = train_labels[seen_labels_index_train].reshape(len(seen_labels_index_train)).tolist()\n",
    "seen_embeddings_train = train_features_norm[seen_labels_index_train]\n",
    "\n",
    "#Final train data\n",
    "train_embeddings = seen_embeddings_train\n",
    "train_labels = seen_labels_train\n",
    "\n",
    "#final validation data\n",
    "validation_embeddings = np.vstack((validation_features_norm, unseen_embeddings_train))\n",
    "validation_labels = np.concatenate((validation_labels, unseen_labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc2621",
   "metadata": {},
   "source": [
    "verifying shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71fe873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7185, 3840)\n",
      "7185\n",
      "(2043, 3840)\n",
      "2043\n"
     ]
    }
   ],
   "source": [
    "#print(train_embeddings)\n",
    "print(train_embeddings.shape)\n",
    "#print(train_labels)\n",
    "print(len(train_labels))\n",
    "#print(validation_embeddings)\n",
    "print(validation_embeddings.shape)\n",
    "#print(validation_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab28eb",
   "metadata": {},
   "source": [
    "Apply Logistic Regression in one-vs-all fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcab994",
   "metadata": {},
   "source": [
    "LR with cost 10 and liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b092b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(len(validation_labels))\n",
    "clf = LogisticRegression(C = 10, solver = 'liblinear', class_weight = 'balanced', random_state=0)\n",
    "conf_matrix = np.zeros((len(validation_labels), len(unique_seen_labels)))\n",
    "for j in range(len(unique_seen_labels)):\n",
    "    positive_labels_index = np.argwhere(np.isin(train_labels, unique_seen_labels[j])).ravel()\n",
    "    negative_labels_index = list(set(range(len(train_labels))) - set(positive_labels_index))\n",
    "    positive_labels_embedding = train_embeddings[positive_labels_index]\n",
    "    negative_labels_embedding = train_embeddings[negative_labels_index]\n",
    "    positive_labels = unique_seen_labels[j]*np.ones(len(positive_labels_index))\n",
    "    negative_labels = -1*np.ones(len(negative_labels_index))\n",
    "    train_embeddings_one = np.vstack((positive_labels_embedding, negative_labels_embedding))\n",
    "    #print(train_embeddings_one)\n",
    "    train_labels_one = np.concatenate((positive_labels, negative_labels))\n",
    "    #print(train_labels_one)\n",
    "    clf.fit(train_embeddings_one, train_labels_one)\n",
    "    conf_score = clf.decision_function(validation_embeddings)\n",
    "    #print(conf_score)\n",
    "    conf_matrix[:,j] = conf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147648dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2043, 963)\n"
     ]
    }
   ],
   "source": [
    "print(conf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9267f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean class accuracy\n",
    "def mean_class_acc(predictions, true_labels):\n",
    "    matrix = confusion_matrix(true_labels, predictions)\n",
    "    acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a50330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost parameter: 10\n",
      "Overall Accuracy: 0.5286343612334802\n",
      "Mean class accuracy: 0.7786184365157712\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(C = 10, solver = 'liblinear', class_weight = 'balanced', random_state=0)\n",
    "clf_lr.fit(train_embeddings, train_labels)\n",
    "preds = clf_lr.predict(validation_embeddings)\n",
    "score = clf_lr.score(validation_embeddings, validation_labels)\n",
    "print(\"Cost parameter:\", 10)\n",
    "print(\"Overall Accuracy:\", score)\n",
    "mean_acc = mean_class_acc(preds, validation_labels)\n",
    "print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb19d9e",
   "metadata": {},
   "source": [
    "threshold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02591d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification f1 score:  0.7009511467649253\n",
      "OOD f1 score:  0.6542857142857142\n",
      "Harmonic mean:  0.6768150054374042\n"
     ]
    }
   ],
   "source": [
    "predictions_all = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0:\n",
    "        predictions_all[k] = -1\n",
    "    else:\n",
    "        predictions_all[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_all, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f713c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n",
      "Classification f1 score:  0.6997680043045242\n",
      "OOD f1 score:  0.6542857142857142\n",
      "Harmonic mean:  0.6762629905220588\n"
     ]
    }
   ],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517ff8e",
   "metadata": {},
   "source": [
    "thr -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5080f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_lr.predict(validation_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a0a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification f1 score:  0.7050878297669961\n",
      "OOD f1 score:  0.6517664023071377\n",
      "Harmonic mean:  0.677379407831149\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.1:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe846ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n",
      "Classification f1 score:  0.7039046873065951\n",
      "OOD f1 score:  0.6517664023071377\n",
      "Harmonic mean:  0.676832941452885\n"
     ]
    }
   ],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.1:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82813a",
   "metadata": {},
   "source": [
    "thr -0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be2efee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_lr.predict(validation_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1372fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification f1 score:  0.7080640961511983\n",
      "OOD f1 score:  0.6487272727272727\n",
      "Harmonic mean:  0.6770981899626335\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.15:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6148ec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605\n",
      "Classification f1 score:  0.7068809536907972\n",
      "OOD f1 score:  0.6487272727272727\n",
      "Harmonic mean:  0.6765567577623426\n"
     ]
    }
   ],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.15:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa681034",
   "metadata": {},
   "source": [
    "thr 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0fa24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_lr.predict(validation_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096dc32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification f1 score:  0.6990013781012306\n",
      "OOD f1 score:  0.6600706713780918\n",
      "Harmonic mean:  0.6789784384341583\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0.1:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef0267ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n",
      "Classification f1 score:  0.6978182356408296\n",
      "OOD f1 score:  0.6600706713780918\n",
      "Harmonic mean:  0.6784197866532826\n"
     ]
    }
   ],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0.1:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb122e4",
   "metadata": {},
   "source": [
    "thr 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8dfac63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_lr.predict(validation_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4717a65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification f1 score:  0.6871206269394496\n",
      "OOD f1 score:  0.6800804828973843\n",
      "Harmonic mean:  0.6835824289719938\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0.5:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca916a3",
   "metadata": {},
   "source": [
    "above is the best result from one vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59c0b265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721\n",
      "Classification f1 score:  0.6854193514063986\n",
      "OOD f1 score:  0.6800804828973843\n",
      "Harmonic mean:  0.6827394801250093\n"
     ]
    }
   ],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0.5:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d38d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e00fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_lr.predict(validation_embeddings)\n",
    "output_df = pd.DataFrame(preds)\n",
    "output_df.to_csv('Task3_preds_numerical_LR_c10_liblinear_normalized.csv', index=False,  header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad2aed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0       0\n",
      "1       1\n",
      "2       2\n",
      "3       3\n",
      "4       4\n",
      "...   ...\n",
      "2038  988\n",
      "2039  988\n",
      "2040  988\n",
      "2041  985\n",
      "2042  988\n",
      "\n",
      "[2043 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "LR_pred = pd.read_csv('Task3_preds_numerical_LR_c10_liblinear_normalized.csv', header = None)\n",
    "print(LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23547b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(conf_matrix)\n",
    "for k in range(len(validation_labels)):\n",
    "    if max(conf_matrix[k]) < 0:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "\n",
    "        #calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fed1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa3ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
