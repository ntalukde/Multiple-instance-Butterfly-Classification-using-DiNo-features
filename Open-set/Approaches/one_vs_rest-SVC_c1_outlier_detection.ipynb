{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d815b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.stats import multivariate_t\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce433329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "whole = sio.loadmat('whole_wolabels.mat')\n",
    "parts = sio.loadmat('parts_wolabels.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee21377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "#This function is used to encode labels since labels are categorical.\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "#Harmonic mean calculation\n",
    "def Harmonic_Mean(ytest, ypred, ytrain):\n",
    "    ytest = np.array(ytest)\n",
    "    ypred = np.array(ypred)\n",
    "    true_dict = Counter(ytest)\n",
    "    prediction_dict = Counter(ypred)\n",
    "    uytest = set(ytest) #all classes present during testing may contain unseen classes and only a subset of the seen classes\n",
    "    uytrain = set(ytrain) #classes represented during training, seen classes\n",
    "    \n",
    "    #Classification f1 score\n",
    "    uy = list(uytest.intersection(uytrain))\n",
    "    nc = len(uy)\n",
    "    Classification_F1 = np.zeros(nc)\n",
    "    for i in range(nc):\n",
    "        Index_of_i_th_class_true = list(np.argwhere(ytest == uy[i]).ravel())\n",
    "        Index_of_i_th_class_pred = list(np.argwhere(ypred == uy[i]).ravel())\n",
    "        tp = len(list(set(Index_of_i_th_class_true).intersection(Index_of_i_th_class_pred)))\n",
    "        #print(\"tp: \", tp)\n",
    "        fp = prediction_dict[uy[i]] - tp\n",
    "        #print(\"fp: \", fp)\n",
    "        fn = true_dict[uy[i]] - tp\n",
    "        #print(\"fn: \", fn)\n",
    "        Classification_F1[i] = (2*tp)/(2*tp + fp + fn)\n",
    "    Classification_F1_mean = np.mean(Classification_F1)\n",
    "    \n",
    "    #Out of distribution f1 score\n",
    "    uy = set(uy)\n",
    "    u_unseen_classes = list(uytest - uy)\n",
    "    Index_of_unseen_class_true = list(np.argwhere(np.isin(ytest, u_unseen_classes)).ravel())\n",
    "    Index_of_unseen_class_pred = list(np.argwhere(ypred == -1).ravel())\n",
    "    tp = len(list(set(Index_of_unseen_class_true).intersection(Index_of_unseen_class_pred)))\n",
    "    fp = len(Index_of_unseen_class_pred) - tp\n",
    "    fn = len(Index_of_unseen_class_true) - tp\n",
    "    OOD_F1 = (2*tp)/(2*tp + fp + fn)\n",
    "    \n",
    "    harmonic_mean = 2*Classification_F1_mean*OOD_F1/(Classification_F1_mean+OOD_F1) #harmonic mean of the two scores\n",
    "    \n",
    "    return Classification_F1_mean, OOD_F1, harmonic_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17954096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "#whole\n",
    "\n",
    "#train\n",
    "train_classid = np.squeeze(whole['train_classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = whole['train_feats']\n",
    "train_imid = whole['train_imgid']\n",
    "train_imgid = []\n",
    "for item in train_imid:\n",
    "    train_imgid.append(item[0])\n",
    "train_imgid = np.squeeze(train_imgid)\n",
    "train_sampleid = whole['train_sampleid']\n",
    "\n",
    "#validation\n",
    "validation_classid = np.squeeze(whole['val_classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = whole['val_feats']\n",
    "validation_imid = whole['val_imgid']\n",
    "validation_imgid = []\n",
    "for item in validation_imid:\n",
    "    validation_imgid.append(item[0])\n",
    "validation_imgid = np.squeeze(validation_imgid)\n",
    "validation_sampleid = whole['val_sampleid']\n",
    "\n",
    "#test\n",
    "test_features = whole['test_feats']\n",
    "test_imid = whole['test_imgid']\n",
    "test_imgid = []\n",
    "for item in test_imid:\n",
    "    test_imgid.append(item[0])\n",
    "test_imgid = np.squeeze(test_imgid)\n",
    "test_sampleid = whole['test_sampleid']\n",
    "\n",
    "#encoded train labels\n",
    "train_labels, le = encode_labels(train_class_labels)\n",
    "train_unique_labels = sorted(np.unique(train_labels))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(len(train_labels))\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels = le.transform(validation_class_labels)\n",
    "validation_unique_labels = sorted(np.unique(validation_labels))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5b24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parts\n",
    "\n",
    "#train\n",
    "train_classid_parts = np.squeeze(parts['train_classid'])\n",
    "train_class_labels_parts = []\n",
    "for item in train_classid_parts:\n",
    "    train_class_labels_parts.append(item[0])\n",
    "train_features_parts = parts['train_feats']\n",
    "train_imid_parts = parts['train_imgid']\n",
    "train_imgid_parts = []\n",
    "for item in train_imid_parts:\n",
    "    train_imgid_parts.append(item[0])\n",
    "train_imgid_parts = np.squeeze(train_imgid_parts)\n",
    "train_sampleid_parts = parts['train_sampleid']\n",
    "train_tileid_parts = parts['train_tileid']\n",
    "\n",
    "#validation\n",
    "validation_classid_parts = np.squeeze(parts['val_classid'])\n",
    "validation_class_labels_parts = []\n",
    "for item in validation_classid_parts:\n",
    "    validation_class_labels_parts.append(item[0])\n",
    "validation_features_parts = parts['val_feats']\n",
    "validation_imid_parts = parts['val_imgid']\n",
    "validation_imgid_parts = []\n",
    "for item in validation_imid_parts:\n",
    "    validation_imgid_parts.append(item[0])\n",
    "validation_imgid_parts = np.squeeze(validation_imgid_parts)\n",
    "validation_sampleid_parts = parts['val_sampleid']\n",
    "validation_tileid_parts = parts['val_tileid']\n",
    "\n",
    "#test\n",
    "test_features_parts = parts['test_feats']\n",
    "test_imid_parts = parts['test_imgid']\n",
    "test_imgid_parts = []\n",
    "for item in test_imid_parts:\n",
    "    test_imgid_parts.append(item[0])\n",
    "test_imgid_parts = np.squeeze(test_imgid_parts)\n",
    "test_sampleid_parts = parts['test_sampleid']\n",
    "test_tileid_parts = parts['test_tileid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47b1d4",
   "metadata": {},
   "source": [
    "combine labels to find outlier percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31ae270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9228\n"
     ]
    }
   ],
   "source": [
    "# combine train and validation data labels\n",
    "total_labels = np.array(list(train_labels) + list(validation_labels))\n",
    "print(len(total_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c69d5",
   "metadata": {},
   "source": [
    "Converting into bag representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7919e0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70641 384\n",
      "(7849, 9, 384)\n",
      "12411 384\n",
      "(1379, 9, 384)\n"
     ]
    }
   ],
   "source": [
    "train_n, d = train_features_parts.shape\n",
    "print(train_n, d)\n",
    "train_features_parts_bags = train_features_parts.reshape(int(train_n/9), 9, d)\n",
    "print(train_features_parts_bags.shape)\n",
    "\n",
    "validation_n, d = validation_features_parts.shape\n",
    "print(validation_n,d)\n",
    "validation_features_parts_bags = validation_features_parts.reshape(int(validation_n/9), 9, d)\n",
    "print(validation_features_parts_bags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277368e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 3840)\n",
      "(1379, 3840)\n"
     ]
    }
   ],
   "source": [
    "combined_train_features = []\n",
    "combined_validation_features = []\n",
    "\n",
    "for i in range(len(train_features_parts_bags)):\n",
    "    combined_train_features.append(np.concatenate((train_features[i], train_features_parts_bags[i]), axis=None))\n",
    "combined_train_features = np.array(combined_train_features)\n",
    "print(combined_train_features.shape)\n",
    "\n",
    "for i in range(len(validation_features_parts_bags)):\n",
    "    combined_validation_features.append(np.concatenate((validation_features[i], validation_features_parts_bags[i]), axis=None))\n",
    "combined_validation_features = np.array(combined_validation_features)\n",
    "print(combined_validation_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604485d",
   "metadata": {},
   "source": [
    "Create holdout dataset for outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81a7431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_unseen_labels: [720, 828, 898, 907, 926, 984, 13, 16, 25, 33, 39, 49, 51, 60, 61, 78, 84, 86, 88, 89, 100, 103, 106, 107, 110, 111, 113, 116, 121, 132, 134, 145, 146, 148, 152, 154, 158, 168, 175, 177, 199, 205, 207, 209, 212, 221, 222, 225, 227, 232]\n",
      "unseen_labels length: 770\n",
      "unique_seen_labels length: 963\n",
      "seen_labels index train length: 7185\n"
     ]
    }
   ],
   "source": [
    "validation_count_dict = Counter(validation_labels)\n",
    "#print(validation_count_dict)\n",
    "\n",
    "validation_labels_dict = sorted(validation_count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "unique_unseen_labels = []\n",
    "for i in range(64,114):\n",
    "      unique_unseen_labels.append(validation_labels_dict[i][0])\n",
    "print(\"unique_unseen_labels:\", unique_unseen_labels)\n",
    "\n",
    "unseen_labels_index = np.argwhere(np.isin(total_labels, unique_unseen_labels)).ravel()\n",
    "print(\"unseen_labels length:\", len(unseen_labels_index))\n",
    "\n",
    "#separating unseen classes from train data\n",
    "unseen_labels_index_train = np.argwhere(np.isin(train_labels, unique_unseen_labels)).ravel()\n",
    "unseen_labels_train = train_labels[unseen_labels_index_train]\n",
    "unseen_embeddings_train = combined_train_features[unseen_labels_index_train]\n",
    "\n",
    "#separating seen classes from train data\n",
    "unique_seen_labels = sorted(list(set(train_unique_labels) - set(unique_unseen_labels)))\n",
    "print(\"unique_seen_labels length:\", len(unique_seen_labels))\n",
    "\n",
    "seen_labels_index_train = np.argwhere(np.isin(train_labels, unique_seen_labels)).ravel()\n",
    "print(\"seen_labels index train length:\", len(seen_labels_index_train))\n",
    "seen_labels_train = train_labels[seen_labels_index_train].reshape(len(seen_labels_index_train)).tolist()\n",
    "seen_embeddings_train = combined_train_features[seen_labels_index_train]\n",
    "\n",
    "#Final train data\n",
    "train_embeddings = seen_embeddings_train\n",
    "train_labels = seen_labels_train\n",
    "\n",
    "#final validation data\n",
    "validation_embeddings = np.vstack((combined_validation_features, unseen_embeddings_train))\n",
    "validation_labels = np.concatenate((validation_labels, unseen_labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17241432",
   "metadata": {},
   "source": [
    "verifying shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c7b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7185, 3840)\n",
      "7185\n",
      "(2043, 3840)\n",
      "2043\n"
     ]
    }
   ],
   "source": [
    "#print(train_embeddings)\n",
    "print(train_embeddings.shape)\n",
    "#print(train_labels)\n",
    "print(len(train_labels))\n",
    "#print(validation_embeddings)\n",
    "print(validation_embeddings.shape)\n",
    "#print(validation_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb112a",
   "metadata": {},
   "source": [
    "Apply SVM in one-vs-all fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbf6ca",
   "metadata": {},
   "source": [
    "SVM classifier with cost 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1391ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(len(validation_labels))\n",
    "clf = make_pipeline(StandardScaler(), SVC(C=1, kernel = 'linear', class_weight='balanced', random_state=0))\n",
    "conf_matrix = np.zeros((len(validation_labels), len(unique_seen_labels)))\n",
    "for j in range(len(unique_seen_labels)):\n",
    "    positive_labels_index = np.argwhere(np.isin(train_labels, unique_seen_labels[j])).ravel()\n",
    "    negative_labels_index = list(set(range(len(train_labels))) - set(positive_labels_index))\n",
    "    positive_labels_embedding = train_embeddings[positive_labels_index]\n",
    "    negative_labels_embedding = train_embeddings[negative_labels_index]\n",
    "    positive_labels = unique_seen_labels[j]*np.ones(len(positive_labels_index))\n",
    "    negative_labels = -1*np.ones(len(negative_labels_index))\n",
    "    train_embeddings_one = np.vstack((positive_labels_embedding, negative_labels_embedding))\n",
    "    #print(train_embeddings_one)\n",
    "    train_labels_one = np.concatenate((positive_labels, negative_labels))\n",
    "    #print(train_labels_one)\n",
    "    clf.fit(train_embeddings_one, train_labels_one)\n",
    "    conf_score = clf.decision_function(validation_embeddings)\n",
    "    #print(conf_score)\n",
    "    conf_matrix[:,j] = conf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240366b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2043, 963)\n"
     ]
    }
   ],
   "source": [
    "print(conf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd330cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean class accuracy\n",
    "def mean_class_acc(predictions, true_labels):\n",
    "    matrix = confusion_matrix(true_labels, predictions)\n",
    "    acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5943fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost parameter: 1\n",
      "Overall Accuracy: 0.5139500734214391\n",
      "Mean class accuracy: 0.7530343628073145\n"
     ]
    }
   ],
   "source": [
    "clf_svm = make_pipeline(StandardScaler(), SVC(C=1, kernel='linear', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight='balanced', verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None))\n",
    "clf_svm.fit(train_embeddings, train_labels)\n",
    "preds = clf_svm.predict(validation_embeddings)\n",
    "score = clf_svm.score(validation_embeddings, validation_labels)\n",
    "print(\"Cost parameter:\", 1)\n",
    "print(\"Overall Accuracy:\", score)\n",
    "mean_acc = mean_class_acc(preds, validation_labels)\n",
    "print(\"Mean class accuracy:\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d5bed",
   "metadata": {},
   "source": [
    "threshold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b998466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification f1 score:  0.5812340131736754\n",
      "OOD f1 score:  0.6865839909808342\n",
      "Harmonic mean:  0.6295319472525087\n"
     ]
    }
   ],
   "source": [
    "predictions_all = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0:\n",
    "        predictions_all[k] = -1\n",
    "    else:\n",
    "        predictions_all[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_all, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc51cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n",
      "Classification f1 score:  0.5806923257161002\n",
      "OOD f1 score:  0.6865839909808342\n",
      "Harmonic mean:  0.6292140857824445\n"
     ]
    }
   ],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < 0:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f65e59",
   "metadata": {},
   "source": [
    "threshold -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93366da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros(len(validation_embeddings))\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.1:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "        \n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f37967",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_final = preds\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.1:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f97b2",
   "metadata": {},
   "source": [
    "species prediction from LR_liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a02de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         1\n",
      "2         2\n",
      "3         3\n",
      "4         4\n",
      "       ... \n",
      "2038    988\n",
      "2039    988\n",
      "2040    988\n",
      "2041    985\n",
      "2042    988\n",
      "Name: 0, Length: 2043, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "LR_pred = pd.read_csv('Task3_preds_numerical_LR_c10_liblinear_normalized.csv', header = None)[0]\n",
    "print(LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59c25cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n",
      "Classification f1 score:  0.7120638079482344\n",
      "OOD f1 score:  0.6435786435786436\n",
      "Harmonic mean:  0.6760913383091742\n"
     ]
    }
   ],
   "source": [
    "predictions_final = LR_pred\n",
    "for k in range(len(validation_embeddings)):\n",
    "    if max(conf_matrix[k]) < -0.3:\n",
    "        predictions_final[k] = -1\n",
    "        \n",
    "print(list(predictions_final).count(-1))\n",
    "\n",
    "#calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions_final, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfa77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "645\n",
    "Classification f1 score:  0.6978182356408296\n",
    "OOD f1 score:  0.6600706713780918\n",
    "Harmonic mean:  0.6784197866532826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(conf_matrix)\n",
    "for k in range(len(validation_labels)):\n",
    "    if max(conf_matrix[k]) < 0:\n",
    "        predictions[k] = -1\n",
    "    else:\n",
    "        predictions[k] = unique_seen_labels[np.argmax(conf_matrix[k])]\n",
    "\n",
    "        #calculate harmonic mean\n",
    "Classification_F1_mean, OOD_F1, harmonic_mean = Harmonic_Mean(validation_labels, predictions, train_labels)\n",
    "print(\"Classification f1 score: \", Classification_F1_mean)\n",
    "print(\"OOD f1 score: \", OOD_F1)\n",
    "print(\"Harmonic mean: \", harmonic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ea344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ec040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
